# -*- coding: utf-8 -*-
"""Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yN6XxmKOPqoJNtFCggZ7Fl1ChfmbJXtT
"""

import torch
from torch import nn
from transformers import AutoModel, BertTokenizerFast

class BERT(nn.Module):
    def __init__(self):
        super().__init__()
        self.bert = AutoModel.from_pretrained('bert-base-multilingual-cased')
        for param in self.bert.parameters():
            param.requires_grad = False

        self.fc = nn.Linear(768, 2)
        self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, input_ids, attention_mask):
        _, cls_hs = self.bert(
            input_ids,
            attention_mask=attention_mask,
            return_dict=False
        )
        x = self.fc(cls_hs)
        x = self.softmax(x)
        return x

class RelationClassifier:
    def __init__(self, model_path, max_len=128, device=None):
        self.model_path = model_path
        self.max_len = max_len
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.tokenizer = None

    def load_model(self):
        self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased')

        # Load model architecture + weights
        self.model = BERT()
        self.model.load_state_dict(torch.load(self.model_path, map_location=self.device))
        self.model.to(self.device)
        self.model.eval()

    def is_valid_relation(self, text):
        if self.model is None:
            raise ValueError("Call load_model() first.")

        tokens = self.tokenizer.batch_encode_plus(
            [text],
            max_length=self.max_len,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )

        input_ids = tokens['input_ids'].to(self.device)
        attention_mask = tokens['attention_mask'].to(self.device)

        with torch.no_grad():
            logits = self.model(input_ids, attention_mask)
            pred_class = torch.argmax(logits, dim=1).item()

        return bool(pred_class)

# from inference import RelationClassifier
clf = RelationClassifier("bert_relation_model.pt")
clf.load_model()

print(clf.is_valid_relation("PHAXIAM  est  une  société  biopharmaceutique  qui  développe  des  traitements  innovants  contre  les  infections bactériennes résistantes, responsables de nombreuses infections graves. La société s'appuie sur une approche innovante  basée  sur  l'utilisation  de  phages,  des  virus  naturels  tueurs  de  bactéries.  PHAXIAM  développe  un portefeuille de phages ciblant 3 des bactéries les plus résistantes et les plus dangereuses, qui représentent à elles seules plus des deux tiers des infections résistantes nosocomiales : Staphylococcus aureus, Escherichia coli et Pseudomonas aeruginosa."))